{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Problem data\n",
    "\n",
    "This is the first notebook which works on problem data.\n",
    "We use the raw problem data and augment some features which we get from scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "reading data for all the problems that is present in codeforces website. problemset.json contains data for each\n",
    "problem with the following as keys:\n",
    "\n",
    "-> contestId\n",
    "-> index\n",
    "-> name\n",
    "-> type\n",
    "-> tags\n",
    "\n",
    "'''\n",
    "with open('./data/problemset.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "now we are identifying each problem uniquely based on the string which is concatination of contestId + index, \n",
    "final_data is a dictionary containing all the information of the question with the key being the above mentioned\n",
    "unique id.\n",
    "'''\n",
    "final_data = {}\n",
    "for j, i in enumerate(data['result']['problems']):\n",
    "    prob_id = str(i['contestId']) + str(i['index'])\n",
    "    problem_data = {}\n",
    "    problem_data['name'] = i['name']\n",
    "    problem_data['tags'] = i['tags']\n",
    "    if(prob_id not in final_data):\n",
    "        final_data[prob_id] = {}\n",
    "    final_data[prob_id] = problem_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "since the diffuculy of the problem is not given in the api we scrape them from codeforces website.\n",
    "\n",
    "'''\n",
    "s = requests.Session()\n",
    "for i in range(1, 48):\n",
    "    r = s.get('http://codeforces.com/problemset/page/' + str(i))\n",
    "    soup = BeautifulSoup(r.text)\n",
    "    for j in soup.find_all(\"div\", {\"class\" : \"datatable\"}):\n",
    "        for k in j.find_all(\"tr\")[1:]:\n",
    "            try:\n",
    "                name = k.find_all(\"td\", {\"class\" : \"id\"})[0].text.strip()\n",
    "                difficulty = k.find_all(\"span\", {\"class\" : \"ProblemRating\"})[0].text.strip()\n",
    "            except:\n",
    "                continue\n",
    "            final_data[name]['difficulty'] = difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for the problems which does not have the difficulty we fill them with null values\n",
    "'''\n",
    "for i in final_data:\n",
    "    if('difficulty' not in final_data[i]):\n",
    "        final_data[i]['difficulty'] = None\n",
    "        \n",
    "'''\n",
    "now the final_data is stored in the file called problems.josn.\n",
    "'''\n",
    "with open('./data/problems.json', 'w') as fp:\n",
    "    json.dump(final_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
